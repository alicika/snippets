{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim\n",
    "import helper\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training loss: 0.702928542089996\n",
      "Training loss: 0.45390555446844366\n",
      "Training loss: 0.406671710074075\n",
      "Training loss: 0.3791350293705967\n",
      "Training loss: 0.3587376464690481\n",
      "Training loss: 0.34361811175243434\n",
      "Training loss: 0.32974998498839864\n",
      "Training loss: 0.31544892341375097\n",
      "Training loss: 0.3051650591734757\n",
      "Training loss: 0.29610081864540766\n",
      "Training loss: 0.2865430023322609\n",
      "Training loss: 0.2795352246413734\n",
      "Training loss: 0.2714412099183368\n",
      "Training loss: 0.264362565593234\n",
      "Training loss: 0.2580970384831876\n",
      "Training loss: 0.2515044737456323\n",
      "Training loss: 0.2459552714200035\n",
      "Training loss: 0.24005362814042105\n",
      "Training loss: 0.23534967822195496\n",
      "Training loss: 0.22850460575015813\n",
      "Training loss: 0.22555135240925273\n",
      "Training loss: 0.22130157305265286\n",
      "Training loss: 0.2150316550446027\n",
      "Training loss: 0.21004007744795478\n",
      "Training loss: 0.2064363785516987\n",
      "Training loss: 0.20205006995863878\n",
      "Training loss: 0.1974174146339901\n",
      "Training loss: 0.19391762865568274\n",
      "Training loss: 0.1885334512016285\n",
      "Training loss: 0.1853690920258636\n",
      "Training loss: 0.18111279342514175\n",
      "Training loss: 0.17765561284533124\n",
      "Training loss: 0.17355892090782174\n",
      "Training loss: 0.17023615116503701\n",
      "Training loss: 0.16741066653607115\n",
      "Training loss: 0.16344706038596915\n",
      "Training loss: 0.16183190708006942\n",
      "Training loss: 0.15627047429874\n",
      "Training loss: 0.15482564418435668\n",
      "Training loss: 0.15190456104256325\n",
      "Training loss: 0.14801033098758984\n",
      "Training loss: 0.14656270489191958\n",
      "Training loss: 0.14212732812735254\n",
      "Training loss: 0.1387413048278739\n",
      "Training loss: 0.1359865673954712\n",
      "Training loss: 0.1334187872687986\n",
      "Training loss: 0.13250433678216517\n",
      "Training loss: 0.13018712954822062\n",
      "Training loss: 0.12567997736278486\n",
      "Training loss: 0.12338875699192603\n",
      "Training loss: 0.12263692684396148\n",
      "Training loss: 0.11943274762914348\n",
      "Training loss: 0.1160579061508973\n",
      "Training loss: 0.11255873390225205\n",
      "Training loss: 0.11100658562296489\n",
      "Training loss: 0.1087657772868411\n",
      "Training loss: 0.10685364226661702\n",
      "Training loss: 0.10741343693350995\n",
      "Training loss: 0.10207764145785145\n",
      "Training loss: 0.10138349761979888\n",
      "Training loss: 0.09843416413220801\n",
      "Training loss: 0.09590139833868726\n",
      "Training loss: 0.09405538076356149\n",
      "Training loss: 0.09228074433319747\n",
      "Training loss: 0.09172504987698724\n",
      "Training loss: 0.08859069551974694\n",
      "Training loss: 0.08740540553650844\n",
      "Training loss: 0.08386364380177706\n",
      "Training loss: 0.08347414144134122\n",
      "Training loss: 0.08131768835608218\n",
      "Training loss: 0.08009701300271427\n",
      "Training loss: 0.07761500125377575\n",
      "Training loss: 0.07646212849402621\n",
      "Training loss: 0.07640059259005272\n",
      "Training loss: 0.0718501276288952\n",
      "Training loss: 0.07288525106389322\n",
      "Training loss: 0.06973337343355804\n",
      "Training loss: 0.07032994942060475\n",
      "Training loss: 0.06548432267925292\n",
      "Training loss: 0.06677105286315496\n",
      "Training loss: 0.06698791860743786\n",
      "Training loss: 0.06423175660595457\n",
      "Training loss: 0.06419983126375992\n",
      "Training loss: 0.06208040536309817\n",
      "Training loss: 0.059837667521204486\n",
      "Training loss: 0.058467455110006304\n",
      "Training loss: 0.06017018793493823\n",
      "Training loss: 0.05720653511243247\n",
      "Training loss: 0.053587738451595576\n",
      "Training loss: 0.053186785537195504\n",
      "Training loss: 0.052965479046066626\n",
      "Training loss: 0.052440474330108046\n",
      "Training loss: 0.05129140341924483\n",
      "Training loss: 0.048268992316299504\n",
      "Training loss: 0.044574699769201656\n",
      "Training loss: 0.048111095001349156\n",
      "Training loss: 0.04591064468703306\n",
      "Training loss: 0.045080927259940055\n",
      "Training loss: 0.04245948726035802\n",
      "Training loss: 0.043071994568277865\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=-1))\n",
    "epochs = 100\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.03)\n",
    "\n",
    "for i in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        print(\"Training loss: {}\" .format(running_loss/len(trainloader)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}